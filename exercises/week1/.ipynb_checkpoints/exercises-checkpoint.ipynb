{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 1 - What is an inverse problem?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix inversion\n",
    "\n",
    "We want to solve a system of linear equations $Ku = f$ with :\n",
    "\n",
    "1. $$K = \\left(\\begin{matrix} 1 & 2 \\\\ 2 & 1\\end{matrix}\\right), \\quad f = \\left(\\begin{matrix} 1 \\\\ 1 \\end{matrix}\\right),$$\n",
    "\n",
    "2. $$K = \\left(\\begin{matrix} 1 & 1 \\\\ 1 & 1.001\\end{matrix}\\right), \\quad f = \\left(\\begin{matrix} 1 \\\\ 1 \\end{matrix}\\right),$$\n",
    "\n",
    "3. $$K = \\left(\\begin{matrix} 1 & 1 \\\\ 2 & 1 \\\\ 2 & 2\\end{matrix}\\right), \\quad f = \\left(\\begin{matrix} 1 \\\\ 1 \\\\ 1\\end{matrix}\\right),$$\n",
    "\n",
    "4. $$K = \\left(\\begin{matrix} 1 & 1 \\\\ 2 & 1 \\\\ 2 & 2\\end{matrix}\\right), \\quad f = \\left(\\begin{matrix} 1 \\\\ 2 \\\\ 2\\end{matrix}\\right),$$\n",
    "\n",
    "5. $$K = \\left(\\begin{matrix} 1 & 2 & 1\\\\ 2 & 0 & 2\\end{matrix}\\right), \\quad f = \\left(\\begin{matrix} 1 \\\\ 1 \\end{matrix}\\right),$$\n",
    "\n",
    "6. $$K = \\left(\\begin{matrix} 1 & 0 \\\\ 0 & 0\\end{matrix}\\right), \\quad f = \\left(\\begin{matrix} 0 \\\\ 1 \\end{matrix}\\right),$$\n",
    "\n",
    "Is the system ill-posed? why? You can easily compute eigenvalues and vectors numerically, for example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The eigenvalues are: [ 3. -1.]\n",
      "The eigenvectors are: [0.70710678 0.70710678] [-0.70710678  0.70710678]\n",
      "1: Well posed\n",
      "2: Near singular\n",
      "3: No solution\n",
      "4: Well posed, rank deficient\n",
      "5: Infinite amount of solutions\n",
      "6: Singular\n"
     ]
    }
   ],
   "source": [
    "K = np.array([[1,2],[2,1]])\n",
    "f = np.array([1,1])\n",
    "\n",
    "l, V = np.linalg.eig(K)\n",
    "print(\"The eigenvalues are:\", l)\n",
    "print(\"The eigenvectors are:\",V[:,0], V[:,1])\n",
    "\n",
    "print(\"1: Well posed\")\n",
    "print(\"2: Near singular\")\n",
    "print(\"3: No solution\")\n",
    "print(\"4: Well posed, rank deficient\")\n",
    "print(\"5: Infinite amount of solutions\")\n",
    "print(\"6: Singular\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix inversion II\n",
    "\n",
    "Given a symmetric, positive definite matrix $K \\in \\mathbb{R}^{n\\times n}$ we want to solve $Ku = f$. Such a matrix can be decomposed as\n",
    "$$K = \\sum_{i=1}^n \\lambda_i k_ik_i^T,$$\n",
    "where $\\lambda_1\\geq \\lambda_2 \\geq \\ldots \\geq \\lambda_n > 0$ are the eigenvalues and $k_i$ denote the eigenvectors. Such a matrix has an inverse given by \n",
    "$$K^{-1} = \\sum_{i=1}^n \\lambda_i^{-1} k_ik_i^T.$$\n",
    "\n",
    "To study the well-posedness of the equation we want to bound the *backward error* $\\|u - u^\\delta\\|_2$ in terms of the *forward error* $\\|f - f^{\\delta}\\|_2$ where $Ku = f$ and $Ku^{\\delta} = f^\\delta$.\n",
    "\n",
    "1. Show that $$\\|u - u^\\delta\\|_2 \\leq \\lambda_n^{-1} \\|f - f^{\\delta}\\|_2.$$\n",
    "2. Show that the *relative error* is bounded by\n",
    "$$\\frac{\\|u - u^\\delta\\|_2}{\\|u\\|_2} \\leq \\lambda_1\\lambda_n^{-1} \\frac{\\|f - f^{\\delta}\\|_2}{\\|f\\|_2}.$$\n",
    "3. Compute the condition numbers for the matrices 1, 2 and 6 in the previous excercise; what do you notice?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 1:\n",
    "$$\n",
    "    \\|u - u^\\delta\\|_2  =\\|K^{-1}(f-f^{\\delta})\\| \\\\\n",
    "                        \\leq \\|K^{-1}\\|\\|(f-f^{\\delta})\\| \\\\\n",
    "                        = \\|\\max_i \\lambda_i^{-1}\\|\\|(f-f^{\\delta})\\| \\\\\n",
    "                        = \\lambda_n^{-1} \\|f - f^{\\delta}\\|_2.\n",
    "$$\n",
    "where we used to the symmetry of $K$ and thus $K^{-1}$ for $\\|K^{-1}\\|= \\|\\max_i \\lambda_i^{-1}\\|$\n",
    "\n",
    "Exercise 1:\n",
    "Similarly to exercise 1 we have\n",
    "$$\n",
    "\\|f\\| \\leq \\|K\\|\\|u\\| = \\|\\max_i \\lambda_i\\|\\|u\\| = \\lambda_1\\|u\\|\n",
    "$$\n",
    "This is equivalent to\n",
    "$$\n",
    "1/\\|u\\| \\leq \\lambda_1 1/\\|f\\|\n",
    "$$\n",
    "Therefore\n",
    "$$\n",
    "\\frac{\\|u - u^\\delta\\|}{\\|u\\|} \\leq \\frac{\\lambda_1}{\\|f\\|}\\lambda_n^{-1}\\|f - f^{\\delta}\\| = \\lambda_1\\lambda_n^{-1} \\frac{\\|f - f^{\\delta}\\|_2}{\\|f\\|_2}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Differentiation\n",
    "\n",
    "We are given a function $f \\in C^1([0,1])$ with $f(0) =0$ and want to solve the following inverse problem\n",
    "\n",
    "$$ Ku(x) \\equiv \\int_0^{x} u(x')\\mathrm{d}x' = f(x), \\quad \\text{for} \\quad x \\in [0,1].$$\n",
    "\n",
    "It is readily verified that we can find a (unique) solution by differentiation: $u(x) = f'(x)$. To study well-posedness of the problem, we consider *noisy* measurements $f^{\\delta}(x) = f(x) + \\delta\\sin(k x /\\delta)$ for fixed  arbitrary $k$ and small $\\delta > 0$.\n",
    "\n",
    "1. Show that the *forward error* $f - f^{\\delta}$ is bounded in the $L^{\\infty}$ norm, in particular $\\|f - f^{\\delta}\\|_{L^{\\infty}([0,1])} = \\delta$.\n",
    "2. Show that the *backward error* $u - u^{\\delta}$ can be arbirarily large, even if $\\delta\\downarrow 0$: $\\|u - u^{\\delta}\\|_{L^{\\infty}([0,1])} = k$.\n",
    "\n",
    "Recall that\n",
    "$$\\|g\\|_{L^{\\infty}([0,1])} = \\sup_{x\\in[0,1]} |g(x)|.$$\n",
    "\n",
    "This shows that the problem is *ill-conditioned*; a small forward error does not guarantee a small backward error, implying that the inverse map is not continuous."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 1:\n",
    "$$\n",
    "    \\|f-f^{\\delta}\\|_{L^{\\infty}([0,1])} = \\|\\delta\\sin(kx/\\delta)\\|_{L^{\\infty}([0,1])} = \\delta\n",
    "$$\n",
    "when $\\delta$ small enough such that $$kx/\\delta\\leq \\pi\\delta/2k$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Differentiation II\n",
    "\n",
    "The analysis in the previous exercise depends crucially on the type of noise we allow. If we assume that $n^{\\delta} = f - f^{\\delta}$ is bounded by $\\delta$ in a different norm, we can get a well-posed problem.\n",
    "\n",
    "1. Assuming that $\\|n^{\\delta}\\|_{C^1([0,1])} = \\delta$, show that $\\|u - u^{\\delta}\\|_{L^{\\infty}([0,1])} \\rightarrow 0$ when $\\delta \\rightarrow 0$.\n",
    "\n",
    "2. Can you come up with a type of noise that obeys the assumed bound?\n",
    "\n",
    "Recall that\n",
    "$$\\|g\\|_{C^{1}([0,1])} = \\sup_{x\\in[0,1]} |g(x)| + \\sup_{x\\in[0,1]} |g'(x)|.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 1:\n",
    "$$\n",
    "\\|u-u^\\delta\\| = \\|f'-f'^\\delta\\| \\leq \\|n^\\delta\\| = \\delta\n",
    "$$\n",
    "Exercise 2:\n",
    "$$\n",
    "f^\\delta = f+\\delta x \\\\\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
